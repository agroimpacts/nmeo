{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c407ce-4941-430f-a349-75421edbee01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Satellite image processing on Sagemaker\n",
    "\n",
    "This notebook explores the use of SageMaker for basic geospatial analysis, including using a STAC browser to query and process cloud-optimized geotiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c83ca-64dc-4e4b-b1cf-82097f9fdf77",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "### Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531c032-b121-44be-a0f6-b9444bdf51e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install geopandas\n",
    "%pip install shapely\n",
    "%pip install --find-links=https://girder.github.io/large_image_wheels --no-cache GDAL\n",
    "%pip install rasterio\n",
    "%pip install Werkzeug==2.3.7\n",
    "%pip install leafmap localtileserver matplotlib==3.6.3 folium==0.13.0\n",
    "%pip install jupyter-server-proxy\n",
    "%pip install sat-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f713f7e-55a1-4666-af88-042e3be00e40",
   "metadata": {},
   "source": [
    "Restart kernel to enable functionality in some of the imports (don't reinstall after restart, go straight to imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00cf0e-fbe1-44ed-860a-da1026963ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from subprocess import run\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import boto3\n",
    "import rasterio as rio\n",
    "\n",
    "from rasterio.features import bounds\n",
    "from rasterio.plot import show\n",
    "from pyproj import Transformer\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "import satsearch\n",
    "\n",
    "proxy_path = f\"studiolab/default/jupyter/proxy/{{port}}\"\n",
    "os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = proxy_path\n",
    "    \n",
    "import localtileserver\n",
    "from localtileserver import get_folium_tile_layer, TileClient, examples\n",
    "import leafmap.foliumap as leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d92c0a-5503-4585-aec0-f270b31791a8",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34796032-6c3d-40cc-8f4c-e9aab30361d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def base_map():\n",
    "    m = leafmap.Map()\n",
    "    m.add_basemap(\"SATELLITE\")\n",
    "    m.add_tile_layer(\n",
    "        url='https://server.arcgisonline.com/ArcGIS/rest/services/' +\\\n",
    "                'World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "        name=\"ESRI\",\n",
    "        attribution=\"ESRI\"\n",
    "    )\n",
    "    return m\n",
    "\n",
    "def poly_box(lon, lat, delta):\n",
    "    c1 = [lon + delta, lat + delta]\n",
    "    c2 = [lon + delta, lat - delta]\n",
    "    c3 = [lon - delta, lat - delta]\n",
    "    c4 = [lon - delta, lat + delta]\n",
    "    geometry = {\"type\": \"Polygon\", \"coordinates\": [[ c1, c2, c3, c4, c1 ]]}\n",
    "    return geometry\n",
    "\n",
    "def get_subset(geotiff_file, geometry):\n",
    "    with rio.Env(aws_session):\n",
    "        with rio.open(geotiff_file) as src:#geo_fp:\n",
    "            \n",
    "            # get bbox from bounds of GeoSeries\n",
    "            poly = gpd.GeoSeries([Polygon(geometry[\"coordinates\"][0])])\\\n",
    "                .set_crs(4326)\\\n",
    "                .to_crs(src.crs)\n",
    "            bbox = bounds(poly)\n",
    "            \n",
    "            window = rio.windows.from_bounds(\n",
    "                bbox[0], bbox[1], bbox[2], bbox[3], transform=src.transform\n",
    "            )\n",
    "            # Actual HTTP range request\n",
    "            subset = src.read(1, window=window, boundless=True)\n",
    "    return subset\n",
    "\n",
    "def plotNDVI(nir, red, filename):\n",
    "    ndvi = (nir-red) / (nir+red)\n",
    "    ndvi[ndvi>1] = 1\n",
    "    plt.imshow(ndvi)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ce556-73bf-4d72-a8bc-5db40c74bebe",
   "metadata": {},
   "source": [
    "## Get administrative areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f87082-bdec-4881-9c2d-5fb92131d6f0",
   "metadata": {},
   "source": [
    "### Download and extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53619e-eeaa-4b21-8d96-9f3ce3f78fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "za_base_url = \"https://biogeo.ucdavis.edu/data/diva/adm/\"\n",
    "za_bounds_file = 'ZMB_adm.zip'\n",
    "\n",
    "data_dir = f\"{os.environ['HOME']}/data\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.isfile(f\"{data_dir}/{za_bounds_file}\"):\n",
    "    !wget {za_base_url}{za_bounds_file} -P {data_dir}\n",
    "    !unzip -o {data_dir}/{za_bounds_file} -d {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41841d50-95be-4346-8a80-d8c74c8b1249",
   "metadata": {},
   "source": [
    "### Read in shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14553f4f-9a5f-4554-9175-5a081dc3ca0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = [f\"{data_dir}/{f}\" for f in os.listdir(data_dir) if \"adm2.shp\" in f]\n",
    "zambia = gpd.read_file(file[0])\n",
    "zambia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797fc74-c9a3-42e0-a6c5-c87269ef7800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = base_map()\n",
    "m.add_gdf(zambia, style={\"color\": \"white\"}, layer_name=\"Zambia\", \n",
    "          zoom_to_layer=True)\n",
    "m.add_gdf(zambia[zambia.NAME_2==\"Kabwe\"], style={\"color\": \"red\"}, \n",
    "          layer_name=\"Kabwe\", zoom_to_layer=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267f528-ab7b-4433-8262-6d12e1104a0e",
   "metadata": {},
   "source": [
    "## Get satellite data\n",
    "\n",
    "We are going to use the Spatio-temporal asset catalog (STAC) and specifically designed STAC browsers to query Sentinel-2 imagery available on AWS. Here we are following examples provided [here](https://www.matecdev.com/posts/landsat-sentinel-aws-s3-python.html). \n",
    "\n",
    "First do a simple query of the whole catalog, to retrieve the number of records in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5432cb-8b6d-47e8-9b12-7dedceff2107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentinel_stac = satsearch.Search.search(\n",
    "    url = \"https://earth-search.aws.element84.com/v0\"\n",
    ")\n",
    "print(\"Found \" + str(sentinel_stac.found()) + \" items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eeb458-8f5c-4744-82f3-47b5e27c8b0f",
   "metadata": {},
   "source": [
    "### Filter for a specific area and time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc61cf1-eab6-494b-bdcb-25b7050ee46d",
   "metadata": {},
   "source": [
    "#### Create ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179df304-45b2-433b-a93d-1c0bc3a17d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xy = zambia[zambia.NAME_2==\"Kabwe\"].geometry.centroid\n",
    "geometry = poly_box(xy.x.iloc[0], xy.y.iloc[0], 0.01)\n",
    "time_range = '2023-04-01/2023-05-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee61fc6-fb4d-402e-a8ce-cd8dba43f798",
   "metadata": {},
   "source": [
    "#### Query STAC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9f49b-6f41-46b1-b398-c1b9199727eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_search = satsearch.Search.search( \n",
    "    url = \"https://earth-search.aws.element84.com/v0\",\n",
    "    intersects = geometry,\n",
    "    datetime = time_range,\n",
    "    collections = ['sentinel-s2-l2a-cogs']\n",
    ")\n",
    "s2_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070241f-1bb5-4684-857c-df104703fc55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentinel_items = s2_search.items()\n",
    "print(sentinel_items.summary())\n",
    "\n",
    "for item in sentinel_items:\n",
    "    red_s3 = item.assets['B04']['href']\n",
    "    print(red_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c52fb2-6e23-4f55-91f0-62c7097a7c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item = sentinel_items[0]\n",
    "print(item.assets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3b18e-3840-4d3e-9c61-4163a5e84f21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Bands 4 and 8 for a spatial subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f3a37-38b8-4169-be47-baaeebd59b67",
   "metadata": {},
   "source": [
    "#### Set-up AWS session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517787a-2537-454c-8e95-988272c9895f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['CURL_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'\n",
    "print(\"Creating AWS Session\")\n",
    "aws_session = rio.session.AWSSession(boto3.Session(), requester_pays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa70c45-24d1-450e-82b4-32035bfff749",
   "metadata": {},
   "source": [
    "#### Convert geometry to GeoSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39c147-8ec5-4028-a5e3-7e20702db818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(red_s3) as src:\n",
    "    src_meta = src.meta\n",
    "\n",
    "geom_poly = gpd.GeoSeries(\n",
    "    [Polygon(geometry[\"coordinates\"][0])]\n",
    ").set_crs(4326).to_crs(src_meta[\"crs\"])\n",
    "bbox = bounds(geom_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3019d84-0f79-45b7-a604-124f58a0e8dd",
   "metadata": {},
   "source": [
    "Where is the ROI in relation to an S2 tile? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530980d0-3590-4d58-aeea-05c112a81b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_extent = src.bounds\n",
    "img_poly = gpd.GeoSeries(\n",
    "    [box(src_extent.left, src_extent.bottom,\n",
    "         src_extent.right, src_extent.top)]\n",
    ")\n",
    "roi_poly = gpd.GeoSeries(\n",
    "    [Polygon(geometry[\"coordinates\"][0])]\n",
    ").set_crs(4326).to_crs(src.crs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# show(subset, ax=ax)\n",
    "img_poly.plot(color=\"green\", ax=ax)\n",
    "roi_poly.plot(color=\"red\", ax=ax)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d137e4-d1b7-4b81-8edb-c9db61a8d831",
   "metadata": {},
   "source": [
    "#### Read in subset from each band and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6e678-53d4-4806-ac42-8831a634397c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redl = []\n",
    "nirl = []\n",
    "ndvil = []\n",
    "for i, item in enumerate(sentinel_items):\n",
    "    red_s3 = item.assets['B04']['href']\n",
    "    nir_s3 = item.assets['B08']['href']\n",
    "    date = item.properties['datetime'][0:10]\n",
    "\n",
    "    print(\"Sentinel item number \" + str(i) + \"/\" + \\\n",
    "          str(len(sentinel_items)) + \" \" + date)\n",
    "    red = get_subset(red_s3, geometry)\n",
    "    nir = get_subset(nir_s3, geometry)\n",
    "    ndvi = (nir - red) / (nir + red + 0.00001)\n",
    "    \n",
    "    redl.append(red)\n",
    "    nirl.append(nir)\n",
    "    ndvil.append(ndvi)\n",
    "    \n",
    "    plotNDVI(\n",
    "        nir, red, \n",
    "        f\"{os.environ['HOME']}/sagemaker-studiolab-notebooks/\"\\\n",
    "        f\"images/{date}_{i}_ndvi.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f07e21-a67e-4692-a657-a582c24d4d4a",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8640c0-61d8-42ac-9075-f2d07827e6c8",
   "metadata": {},
   "source": [
    "1. Calculate median NIR image\n",
    "2. Calculate median red image\n",
    "3. Calculate NDVI from median red and NIR\n",
    "4. Write to geotiff on disk (under data folder)\n",
    "5. Display resulting NDVI image in leafmap using the add_raster function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e876c9d-4d52-49f4-90c8-a91238ce10bc",
   "metadata": {},
   "source": [
    "### Median images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf78c97-cbd1-4cd3-86fc-dac8acf55044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redmed = np.nanmedian(\n",
    "    np.array([np.where(red==0, np.nan, red) for red in redl]), \n",
    "    axis=0\n",
    ")\n",
    "nirmed = np.nanmedian(\n",
    "    np.array([np.where(nir==0, np.nan, nir) for nir in nirl]), \n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9aa5ea-2dca-41c9-b1bc-5217157f76c3",
   "metadata": {},
   "source": [
    "### NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5e10a-514e-474f-bc45-7a451231204f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndvi = (nirmed-redmed) / (nirmed+redmed+0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0d353-511a-45c5-b4f6-d3ba20f8088a",
   "metadata": {},
   "source": [
    "### Write to geotiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d00b5-3b6c-4aa7-bb0e-d1425463233b",
   "metadata": {},
   "source": [
    "#### Get and adjust metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04714be9-5d64-4041-b7f8-73b72e35cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(red_s3) as src:\n",
    "    src_meta = src.meta\n",
    "\n",
    "# src_meta    \n",
    "dst_meta = src_meta.copy()\n",
    "dst_transform = list(src_meta[\"transform\"])[0:6]\n",
    "bbox = bounds(geom_poly)\n",
    "dst_transform[2] = bbox[0]\n",
    "dst_transform[5] = bbox[3]\n",
    "dst_meta[\"dtype\"] = np.float32\n",
    "dst_meta[\"height\"] = ndvi.shape[0]\n",
    "dst_meta[\"width\"] = ndvi.shape[1]\n",
    "dst_meta[\"transform\"] = Affine(*dst_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84e51c-552a-4433-a05e-157c0ffbcb97",
   "metadata": {},
   "source": [
    "#### To disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8e432-c5e0-4034-af8c-5e97f0013f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_file = f\"{data_dir}/ndvi_median.tif\"\n",
    "with rio.open(out_file, 'w+', **dst_meta) as dst:\n",
    "    dst.write(ndvi, 1)\n",
    "\n",
    "show(rio.open(out_file))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bbc71-1e30-4d78-bef2-78dba6d5134e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Map it\n",
    "\n",
    "Note: `add_raster` works when using Google Chrome but the local raster does not show when this is run from Firefox (and also Edge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f277e-1490-46be-b4ab-62cabeecf500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = base_map()\n",
    "m.add_gdf(gpd.GeoDataFrame({\"id\": 1, \"geometry\": geom_poly}), \n",
    "          style={\"color\": \"blue\"}, layer_name=\"ROI\", zoom_to_layer=True)\n",
    "m.add_raster(out_file, cmap=\"PRGn\", layer_name=\"S2 NDVI\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc42454-59f0-480a-8484-a9aa10d4217b",
   "metadata": {},
   "source": [
    "## Create cloud-native assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914946f0-6513-42a8-b1b8-5a6dbf110fea",
   "metadata": {},
   "source": [
    "### Cloud-Optimized Geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affcfc4-3ba0-46aa-ad00-76fdd3eca8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install rio-cogeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eae7de-35c9-4686-a228-1fad609c9d71",
   "metadata": {
    "tags": []
   },
   "source": [
    "Run rio-cogeo to create and validate tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17506a5c-7b4e-4c4e-97f4-30cf396d1189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cog_file = re.sub(\".tif\", \"_cog.tif\", out_file)\n",
    "\n",
    "cmd = ['rio', 'cogeo', 'create', '-b', '1', out_file, cog_file]\n",
    "p = run(cmd, capture_output=True)\n",
    "msg = p.stderr.decode().split('\\n')\n",
    "print(f'...{msg[-2]}')\n",
    "\n",
    "cmd = ['rio', 'cogeo', 'validate', cog_file]\n",
    "p = run(cmd, capture_output = True)\n",
    "msg = p.stdout.decode().split('\\n')\n",
    "print(f'...{msg[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef28694-12bd-4dc0-9de8-4c64d160588b",
   "metadata": {},
   "source": [
    "Check specs of imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37295c87-5e24-46c2-8d81-1dc7cbbd9376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gdalinfo {out_file}\n",
    "!gdalinfo {cog_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7819c-fb41-41f4-9a7e-01b9f088cff2",
   "metadata": {},
   "source": [
    "#### Make an NDVI COG for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e092f4d-3ffa-4b4a-8bca-c9f24ed8cab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(ndvil)):\n",
    "    ndvi_file = re.sub(\"median.tif\", f\"{i}.tif\", out_file)\n",
    "    # ndvi_cog_file = re.sub(f\"{i}.tif\", f\"cog_{i}.tif\", ndvi_file)\n",
    "    print(f\"Making {ndvi_file}\")\n",
    "    \n",
    "    with rio.open(ndvi_file, 'w+', **dst_meta) as dst:\n",
    "        dst.write(ndvil[i], 1)\n",
    "    \n",
    "    cmd = ['rio', 'cogeo', 'create', '-b', '1', ndvi_file, \n",
    "           ndvi_file]\n",
    "    p = run(cmd, capture_output=True)\n",
    "    msg = p.stderr.decode().split('\\n')\n",
    "    print(f'...{msg[-2]}')\n",
    "\n",
    "    cmd = ['rio', 'cogeo', 'validate', ndvi_file]\n",
    "    p = run(cmd, capture_output = True)\n",
    "    msg = p.stdout.decode().split('\\n')\n",
    "    print(f'...{msg[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9e4ab-2699-4ad6-aa68-63a0b215e3ab",
   "metadata": {},
   "source": [
    "### Make the NDVI COGs into a STAC collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387db2d-608a-4811-8ba1-e301f7c3661e",
   "metadata": {},
   "source": [
    "We will adapt the tutorial [here](https://stacspec.org/en/tutorials/2-create-stac-catalog-python/) for this purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d6b4f-56af-43fb-8f2e-3bd7b27c73e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports\n",
    "\n",
    "We already have everything we need installed and imported, except `pystac`, so we start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c78195-9f63-42cd-aae4-c4f12ff14262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pystac\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from shapely.geometry import Polygon, mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c92488-74f7-473d-b1ed-2429da9d9a66",
   "metadata": {},
   "source": [
    "#### Create catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573040ef-9dc3-44b9-ac31-c20026504253",
   "metadata": {},
   "source": [
    "And we have the data we need, so we can jump straight to creating the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0e9e4-395a-486b-84b7-7665c3afe7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac.Catalog(\n",
    "    id='sentinel2-ndvi-catalog', \n",
    "    description='This is a catalog of NDVI subsets from Sentinel-2 over Zambia'\n",
    ")\n",
    "print(list(catalog.get_children()))\n",
    "print(list(catalog.get_items()))\n",
    "print(json.dumps(catalog.to_dict(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196131e0-9451-4688-b590-2296372981ce",
   "metadata": {},
   "source": [
    "#### Get bbox and footprint of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d41ea-5739-4030-ae25-433ec6cd7b32",
   "metadata": {},
   "source": [
    "Using the function provided from the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941b192-a3c3-4b0a-9c91-0bd0c9920765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bbox_and_footprint(image):\n",
    "    with rio.open(image) as r:\n",
    "        bounds = r.bounds\n",
    "        bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
    "        footprint = Polygon([\n",
    "            [bounds.left, bounds.bottom],\n",
    "            [bounds.left, bounds.top],\n",
    "            [bounds.right, bounds.top],\n",
    "            [bounds.right, bounds.bottom]\n",
    "        ])\n",
    "        \n",
    "        return (bbox, mapping(footprint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108761ee-bdcd-4a4f-b981-195ee2476f71",
   "metadata": {},
   "source": [
    "Let's test for one image (the last ndvi image produced in the loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd56c59-bdfd-430a-84a7-112445e3342c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the function and print out the results\n",
    "bbox, footprint = get_bbox_and_footprint(ndvi_file)\n",
    "print(\"bbox: \", bbox, \"\\n\")\n",
    "print(\"footprint: \", footprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6caf9-a2bf-4b35-995c-5c563ff57017",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get image dates\n",
    "\n",
    "Unlike the example in the tutorial, which assigns the current datetime to the image created, we want to get the actual date and time of each image in the collection. Since we didn't capture that the first time, we have two options:\n",
    "\n",
    "1. Go back and redo the subsetting above and capture the date while we are at it.  \n",
    "2. Get the dates from the Sentinel stac collection we read from the public registry. \n",
    "\n",
    "We will do the second approach here. Note that we have to use an extra step to convert the character string containing the date and time object to a python `datetime` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faee728-085a-427f-ae9a-f77eb6022db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datel = []\n",
    "for i, item in enumerate(sentinel_items):\n",
    "    # datetime(item.properties['datetime'])\n",
    "    dtime = datetime.strptime(\n",
    "        item.properties['datetime'], \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    ).replace(tzinfo=timezone.utc)\n",
    "    datel.append(dtime)\n",
    "\n",
    "datel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bda8e6-f536-46e5-bc2a-a2c123263bbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice that now we get both the date and time, not just the date. Since the last image in the collection (which is actually the earliest image) is the one we are working with, we will pull out the last date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13741b3f-0a62-48d5-8319-c9072bc3a2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datel[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38145472-3eda-4275-b1d9-45ad794dfb49",
   "metadata": {},
   "source": [
    "Now we can populate the STAC item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df592e7f-4915-41b7-a1cb-50cbf78b2399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_id = \"S2_\" + re.sub(\".tif\", \"\", os.path.basename(ndvi_file))\n",
    "file_id\n",
    "item = pystac.Item(\n",
    "    id=os.path.basename(file_id),\n",
    "    geometry=footprint,\n",
    "    bbox=bbox,\n",
    "    datetime=datel[-1],\n",
    "    properties={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846721a4-87b5-435e-9c1c-6439b87e0548",
   "metadata": {},
   "source": [
    "#### Add the item to the collection \n",
    "\n",
    "We haven't assigned the item to the collection yet, so it has no parent, as we see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b04b0c-cdc5-418b-8e01-68bd852add10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(item.get_parent() is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c1ffc-0218-4b59-bc0f-faa240ffe470",
   "metadata": {},
   "source": [
    "So let's add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fa01d-d4ab-4da2-90e3-6ae7165bc471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.add_item(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4490c-2f95-42ce-8288-bd05f377f9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item.get_parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044db67-4564-4a72-87f6-aee0497cd034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c199c-e29d-4e9e-a6cc-e95fa9dbc00f",
   "metadata": {},
   "source": [
    "#### Add image asset to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff582ea6-103b-45e1-ad38-ce305b72fc67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Asset and all its information to Item \n",
    "item.add_asset(\n",
    "    key='image',\n",
    "    asset=pystac.Asset(\n",
    "        href=ndvi_file,\n",
    "        media_type=pystac.MediaType.GEOTIFF\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981fcc8-0cbe-4f7d-808e-25d23eabbac6",
   "metadata": {},
   "source": [
    "Check the catalog as `json`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494398db-50ed-4d3b-9eb1-c0b9400469fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(item.to_dict(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967d961-9b67-496a-bd33-3cc75e2f9073",
   "metadata": {},
   "source": [
    "#### Now save the catalog\n",
    "\n",
    "Following the tutorial directions, where we see we need to normalize the references to and in the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688757a-5111-4082-80bd-76393602db42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(catalog.get_self_href() is None)\n",
    "print(item.get_self_href() is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf230c-66b9-4b89-8a91-768e569e3cf5",
   "metadata": {},
   "source": [
    "We use the path to the ndvi_file to do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541aa6d8-a8be-4d10-b2d2-c2c0e6e9d288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.normalize_hrefs(os.path.join(os.path.dirname(ndvi_file), \"stac\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41123a24-299d-44fa-8e2c-981ac0c69636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.get_self_href()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3362a-332e-48d6-b6ef-7d9d6753a3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item.get_self_href()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15d935-bf93-4917-9bfb-26337bc13dfd",
   "metadata": {},
   "source": [
    "##### Save a self-contained version of the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d54715-e579-4349-8b46-1429cab4874b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450a42b-f38c-488a-9da5-bb6c97bfcca7",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can browse to it in the file explorer to have a look at it. We can also open and read it directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85bbdb-e5ff-4ca0-9d63-b75d007f62fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(catalog.self_href) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee4366-a531-4bea-84a4-fa7fb79f7498",
   "metadata": {},
   "source": [
    "Change the published catalog to one that has absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd012ca6-aa51-4347-893f-68b68086de2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.save(catalog_type=pystac.CatalogType.ABSOLUTE_PUBLISHED)\n",
    "with open(item.get_self_href()) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292220b1-9eb4-4cd4-812d-0d82f154b2cd",
   "metadata": {},
   "source": [
    "Change it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732da5e3-af00-4099-8278-53b42157f411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog.make_all_asset_hrefs_relative()\n",
    "catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "\n",
    "with open(item.get_self_href()) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0ffc2-a694-40cb-8c2c-b28decf6f55d",
   "metadata": {},
   "source": [
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50568865-0003-41d5-bc16-93987b562ad0",
   "metadata": {},
   "source": [
    "1. Recreate the STAC catalog here, but add add all NDVI images to it as assets. That means you will need to do that in a loop.  \n",
    "2. Save the catalog as one with absolute paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
